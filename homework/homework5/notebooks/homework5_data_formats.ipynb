{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Data Formats and Storage\n",
    "\n",
    "This notebook demonstrates working with different data formats (CSV and Parquet) and environment-driven configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "DATA_DIR_RAW = Path(os.getenv(\"DATA_DIR_RAW\", \"data/raw\"))\n",
    "DATA_DIR_PROCESSED = Path(os.getenv(\"DATA_DIR_PROCESSED\", \"data/processed\"))\n",
    "\n",
    "for _p in (DATA_DIR_RAW, DATA_DIR_PROCESSED):\n",
    "    _p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def safe_stamp():\n",
    "    return dt.datetime.now().strftime(\"%Y%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_df(df: pd.DataFrame, expect_cols: dict, name: str = \"df\") -> dict:\n",
    "    \"\"\"\n",
    "    expect_cols: {'col_name': 'dtype_hint', ...}\n",
    "      dtype_hint one of: 'datetime', 'float', 'int', 'string', or pandas dtype string\n",
    "    \"\"\"\n",
    "    msgs = {\"name\": name, \"missing_cols\": [], \"bad_dtypes\": {}, \"shape\": df.shape}\n",
    "    for c, t in expect_cols.items():\n",
    "        if c not in df.columns:\n",
    "            msgs[\"missing_cols\"].append(c)\n",
    "        else:\n",
    "            s = df[c]\n",
    "            ok = True\n",
    "            if t == \"datetime\":\n",
    "                try:\n",
    "                    _ = pd.to_datetime(s, errors=\"coerce\")\n",
    "                    ok = _.notna().mean() > 0.9\n",
    "                except Exception:\n",
    "                    ok = False\n",
    "            elif t == \"float\":\n",
    "                ok = pd.to_numeric(s, errors=\"coerce\").notna().mean() > 0.9\n",
    "            elif t == \"int\":\n",
    "                ok = pd.to_numeric(s, errors=\"coerce\").fillna(0).astype(\"int64\").dtype.kind == \"i\"\n",
    "            elif t == \"string\":\n",
    "                ok = s.dtype == \"object\" or pd.api.types.is_string_dtype(s)\n",
    "            else:\n",
    "                ok = str(s.dtype) == t\n",
    "            if not ok:\n",
    "                msgs[\"bad_dtypes\"][c] = f\"expected {t}, got {s.dtype}\"\n",
    "    return msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>182.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>183.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>184.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>181.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>186.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>185.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>187.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date symbol  adj_close\n",
       "0 2024-11-01   AAPL      182.1\n",
       "1 2024-11-02   AAPL      183.9\n",
       "2 2024-11-03   AAPL      184.2\n",
       "3 2024-11-04   AAPL      181.7\n",
       "4 2024-11-05   AAPL      185.0\n",
       "5 2024-11-06   AAPL      186.3\n",
       "6 2024-11-07   AAPL      185.8\n",
       "7 2024-11-08   AAPL      187.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"date\": pd.date_range(\"2024-11-01\", periods=8, freq=\"D\"),\n",
    "    \"symbol\": [\"AAPL\"]*8,\n",
    "    \"adj_close\": [182.1, 183.9, 184.2, 181.7, 185.0, 186.3, 185.8, 187.1]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data in Different Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/raw/sample_20250818-0400.csv'),\n",
       " PosixPath('data/processed/sample_20250818-0400.parquet'),\n",
       " 'pyarrow')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = DATA_DIR_RAW / f\"sample_{safe_stamp()}.csv\"\n",
    "parquet_path = DATA_DIR_PROCESSED / f\"sample_{safe_stamp()}.parquet\"\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "parquet_engine = None\n",
    "for engine in (\"pyarrow\", \"fastparquet\"):\n",
    "    try:\n",
    "        df.to_parquet(parquet_path, index=False, engine=engine)\n",
    "        parquet_engine = engine\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "\n",
    "if parquet_engine is None:\n",
    "    raise RuntimeError(\n",
    "        \"Parquet save failed. Please install one engine:\\n\"\n",
    "        \"  pip install pyarrow   (recommended)\\n\"\n",
    "        \"  or pip install fastparquet\\n\"\n",
    "        f\"Last error: {last_err}\"\n",
    "    )\n",
    "\n",
    "csv_path, parquet_path, parquet_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (8, 3) (8, 3) (8, 3)\n",
      "date         datetime64[ns]\n",
      "symbol               object\n",
      "adj_close           float64\n",
      "dtype: object\n",
      "date         datetime64[ns]\n",
      "symbol               object\n",
      "adj_close           float64\n",
      "dtype: object\n",
      "Validate original: {'name': 'orig', 'missing_cols': [], 'bad_dtypes': {}, 'shape': (8, 3)}\n",
      "Validate csv: {'name': 'csv', 'missing_cols': [], 'bad_dtypes': {}, 'shape': (8, 3)}\n",
      "Validate parquet: {'name': 'parquet', 'missing_cols': [], 'bad_dtypes': {}, 'shape': (8, 3)}\n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv(csv_path, parse_dates=[\"date\"])\n",
    "df_parq = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(\"Shapes:\", df.shape, df_csv.shape, df_parq.shape)\n",
    "print(df_csv.dtypes)\n",
    "print(df_parq.dtypes)\n",
    "\n",
    "expect = {\"date\": \"datetime\", \"symbol\": \"string\", \"adj_close\": \"float\"}\n",
    "print(\"Validate original:\", validate_df(df, expect, \"orig\"))\n",
    "print(\"Validate csv:\", validate_df(df_csv, expect, \"csv\"))\n",
    "print(\"Validate parquet:\", validate_df(df_parq, expect, \"parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df(df: pd.DataFrame, path: Path, index: bool=False):\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    suf = path.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        df.to_csv(path, index=index)\n",
    "        return {\"path\": str(path), \"format\": \"csv\"}\n",
    "    elif suf == \".parquet\":\n",
    "        last_err = None\n",
    "        for engine in (\"pyarrow\", \"fastparquet\"):\n",
    "            try:\n",
    "                df.to_parquet(path, index=index, engine=engine)\n",
    "                return {\"path\": str(path), \"format\": \"parquet\", \"engine\": engine}\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to write parquet at {path}. \"\n",
    "            \"Install an engine: `pip install pyarrow` (recommended) or `pip install fastparquet`. \"\n",
    "            f\"Last error: {last_err}\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported suffix: {suf} (use .csv or .parquet)\")\n",
    "\n",
    "def read_df(path: Path):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    suf = path.suffix.lower()\n",
    "    if suf == \".csv\":\n",
    "        try:\n",
    "            return pd.read_csv(path, parse_dates=[\"date\"])\n",
    "        except Exception:\n",
    "            return pd.read_csv(path)\n",
    "    elif suf == \".parquet\":\n",
    "        return pd.read_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported suffix: {suf} (use .csv or .parquet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'data/raw/sample2_20250818-0400.csv', 'format': 'csv'}\n",
      "{'path': 'data/processed/sample2_20250818-0400.parquet', 'format': 'parquet', 'engine': 'pyarrow'}\n",
      "Shapes: (8, 3) (8, 3) (8, 3)\n",
      "Validate csv2: {'name': 'df', 'missing_cols': [], 'bad_dtypes': {}, 'shape': (8, 3)}\n",
      "Validate par2: {'name': 'df', 'missing_cols': [], 'bad_dtypes': {}, 'shape': (8, 3)}\n"
     ]
    }
   ],
   "source": [
    "p_csv2 = DATA_DIR_RAW / f\"sample2_{safe_stamp()}.csv\"\n",
    "p_par2 = DATA_DIR_PROCESSED / f\"sample2_{safe_stamp()}.parquet\"\n",
    "\n",
    "print(write_df(df, p_csv2))\n",
    "print(write_df(df, p_par2))\n",
    "\n",
    "df_csv2 = read_df(p_csv2)\n",
    "df_par2 = read_df(p_par2)\n",
    "\n",
    "print(\"Shapes:\", df.shape, df_csv2.shape, df_par2.shape)\n",
    "print(\"Validate csv2:\", validate_df(df_csv2, {\"date\":\"datetime\",\"symbol\":\"string\",\"adj_close\":\"float\"}))\n",
    "print(\"Validate par2:\", validate_df(df_par2, {\"date\":\"datetime\",\"symbol\":\"string\",\"adj_close\":\"float\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
